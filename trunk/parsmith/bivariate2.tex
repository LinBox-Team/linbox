
\documentclass[10pt]{article}

\setlength{\textwidth}{5.5in}
\setlength{\textheight}{8.5in}
\setlength{\oddsidemargin}{0pt}
\setlength{\evensidemargin}{0pt}
\setlength{\topmargin}{-.5in}

\newcommand{\Line} {\vspace{1ex} \hrule \vspace{1ex}}
\begin{document}

\begin{center}
\Large{\bf Solving Parametric Linear Systems:\\
the Two Parameter Case} \\[10pt]
Mark Giesbrecht\\
University of Manitoba, Canada\\[5pt]
%\verb|mwg@cs.umanitoba.ca|\\[5pt]
David Saunders \\
University of Delaware, USA \\
%\verb|saunders@udel.edu|
\end{center}

\newtheorem{theorem}{Theorem:}
\newcommand{\jog}{{$~$\indent$~$\indent$~$}}
\newcommand{\jogg}{{\jog\jog}}
\newcommand{\bc}{{$[$}}
\newcommand{\ec}{{$]$}}
\newcommand{\F}{{\mathsf F}}
\newcommand{\K}{{\mathsf K}}
\newcommand{\ints}{{\mathbf Z}}
\newcommand{\RR}{{\cal R}}
\newcommand{\Regime}{{\mbox{Regime}}}
\newcommand{\StPLS}{{SolveTwoParameterLinearSystem$~$}}
\newcommand{\alg}{{\cal A}}
\newcommand{\breg}{\left\{\begin{array}{c}}
\newcommand{\ereg}{\end{array}\right\}}
\newcommand{\implies}{{~~\Rightarrow~~}}
\newcommand{\mxn}{{m\times n}}
\newcommand{\nxn}{{n\times n}}
\newcommand{\kxk}{{k\times k}}
\newcommand{\nx}[1]{{n\times #1}}
\newcommand{\mx}[1]{{m\times #1}}
\newcommand{\rx}[1]{{r\times #1}}
\newcommand{\for}{~\mbox{for}~}
\newcommand{\diag}{~\mbox{diag}~}
\newcommand{\sqfr}{~\mbox{sqfr}~}
\newcommand{\und}{~\mbox{and}~}
\newcommand{\given}{~\mbox{if}~}
\newcommand{\nequiv}{{\mskip4mu\not\equiv\mskip4mu}}
\def\nin{{\mathrel{\hbox{$\mskip4mu\not\in\mskip4mu$}}}}

\section{The problem}

When the coefficients of a system of linear equations are polynomial
expressions in parameters, $x, y, \ldots $ over a field $\K$, the solutions at values of
these parameters in the field (and it's extensions) may be expressed as a 
finite number of
cases.  William Sit, \cite{Sit}, brought attention to the problem of computing a complete set of cases for
this situation and presented an algorithm based on consideration of each square submatrix
in turn.  Following his terminology, we will call the cases  ``regimes''.  Each regime
involves a semi-algebraic set in parameter space and a solution, expressed
rationally in terms of the parameters, which is valid on the semi-algebraic set.
More specifically, the semi-algebraic set is defined by 
a list of polynomial equalities and un-equalities, 
$f_i(x,y, ...) = 0$, $g_j(x,y, ...) \ne 0$.

For example, suppose that we wish to solve $Au = b$ with

\[
A=\left [\begin {array}{ccc} 
1&x&y\\\noalign{\medskip}
y&1&x\\\noalign{\medskip}
x&y&1\end {array}\right ],~ \mbox{and}~
b=\left [\begin {array}{c} 1\\1\\1 \end {array}\right ].
\]
The determinant of $A$ is $ 1-3\,xy+{y}^{3}+{x}^{3} $, so that on the semi-algebraic set consisting of parameter values which are not zeroes of this
polynomial, we have the solution obtained by inverting the matrix,

\[
\{1-3\,xy+{y}^{3}+{x}^{3} \ne 0\}\implies 
u = \left [\begin {array}{c} 
1/(1+x+y)\\\noalign{\medskip}
1/(1+x+y)\\\noalign{\medskip}
1/(1+x+y)
\end {array}\right ].
\]

%\[
%u=\left [\begin {array}{c} -{\frac {-1+xy}{1-3\,xy+{y}^{3}+{x}^{3}}}-{
%\frac {x-{y}^{2}}{1-3\,xy+{y}^{3}+{x}^{3}}}+{\frac {{x}^{2}-y}{1-3\,xy+
%{y}^{3}+{x}^{3}}}\\\noalign{\medskip}-{\frac {-1+xy}{1-3\,xy+{y}^{3}+{x
%}^{3}}}-{\frac {x-{y}^{2}}{1-3\,xy+{y}^{3}+{x}^{3}}}+{\frac {{x}^{2}-y}
%{1-3\,xy+{y}^{3}+{x}^{3}}}\\\noalign{\medskip}-{\frac {-1+xy}{1-3\,xy+{
%y}^{3}+{x}^{3}}}-{\frac {x-{y}^{2}}{1-3\,xy+{y}^{3}+{x}^{3}}}+{\frac {{
%x}^{2}-y}{1-3\,xy+{y}^{3}+{x}^{3}}}\end {array}\right ].
%\]

One also sees by inspection that if $x = y = 1 $ (another semi-algebraic set),
the solution may be expressed by giving a particular solution
and null-space basis.  The rank is 1 so the null space has dimension 2,
and we have 

\[
\breg x = 1\\ y = 1\ereg \implies
u = \left [\begin {array}{c} 1/3\\\noalign{\medskip}1/3\\\noalign{\medskip}1/3 \end {array}\right ]
+ a \left [\begin {array}{c} -1\\\noalign{\medskip}0\\\noalign{\medskip}1 \end {array}\right ]
+ b \left [\begin {array}{c} 0\\\noalign{\medskip}-1\\\noalign{\medskip}1 \end {array}\right ] , 
\for \mbox{arbitrary}~ a \und b.
\]

%u = [1/3,1/3,1/3]^T$ 
%$u_1 = [-1,0,1]^T$ and $u_2 = [-1,0,1]^T$.  In other words, the solution
%in this case is $u = [1/3 - \alpha, 1/3 - \beta, 1/3 + \alpha +\beta]$, 

There may be other solutions of rank 1 or 2.  The goal is to describe all of
them (give a complete set of regimes) and then to make the solution as succinct as reasonably possible.

\newpage
\section{How hard is it?}

Answer:  {\bf Very hard in general} as we illustrate in this section, 
but {\bf not so hard for a fixed number of parameters}, as we show in the 
rest of the paper.

First of all, we note that a minimal number of solution regimes for a given problem instance may be exponential
in the number of parameters.  %For example 
Consider the system
\[ 
\left [\begin {array}{cccc} 
    x_1    & 0      & \ldots & 0      \\\noalign{\medskip}
    0      & x_2    & \ldots & 0      \\\noalign{\medskip}
    \vdots & \vdots & \ddots & \vdots \\\noalign{\medskip}
    0      & 0      & \ldots & x_n    
\end {array}\right ] 
\left [\begin {array}{c} 
    u_{1} \\\noalign{\medskip}
    u_{2} \\\noalign{\medskip}
    \vdots  \\\noalign{\medskip}
    u_{n} 
\end {array}\right ]
=
\left [\begin {array}{c} 
    y_{1} \\\noalign{\medskip}
    y_{2} \\\noalign{\medskip}
    \vdots  \\\noalign{\medskip}
    y_{n} 
\end {array}\right ].
\]

For each choice of subset $I$ of the indices of size $r$,
there is a rank $r$ solution regime on 
the semi-algebraic set, 

\[\begin{array}{ll}
x_{i} \neq 0, & \given i \in I, \\ 
x_{i} = 0, & \given i \notin I, \und \\
y_{i} = 0, & \given i \notin I.
\end{array}\] 
No two of these solutions can be merged.  
Thus $2^n$ regimes are required in all.

Secondly, the problem of computing a minimal number of solution regimes is 
very hard in general.  It is even fundamentally difficult to ensure that 
each regime presented as part of a solution has a non-empty semi-algebraic
set as it's domain.  
For parameters $ P = (p_1, \ldots, p_t)$, Consider the system
\[ 
\left [\begin {array}{cccc} 
    f_1(P)    & f_2(P)  & \ldots & f_n(P)
\end {array}\right ] 
\left [\begin {array}{c} 
    u_{1} \\\noalign{\medskip}
    u_{2} \\\noalign{\medskip}
    \vdots  \\\noalign{\medskip}
    u_{n} 
\end {array}\right ]
=
\left [\begin {array}{c} 
    g(P)
\end {array}\right ].
\]

If $g$ lies in the ideal generated by $f<-1, \ldots, f_n$, it would be possible
to express the rank 1 solution as one regime, giving the $u_i$ as polynomials
in the parameters.  But as 
As Mahr and Meyer \cite{MaMe} have shown, it is exponential space hard to determine if $g$ is in the ideal, and furthermore the minimum size of corresponding $u_i(P)$
can be doubly exponential in the number of variables.
Similarly, in view of Hilbert's Nullstellensatz, 
a diagonal homogeneous system has a rank 0 solution only if
the ideal of the diagonal entries does not contain 1, another hard problem.

Thus necessarily, the polynomial time computation 
presented in this paper, with it's polynomially many solution regimes, does
not guarantee that the set of regimes is minimal or even that each regime
is instantiable.

\newpage
\section{Our claim}

We offer an algorithm which produces in polynomial time a complete set
of solutions when the coefficients are polynomials in two parameters.
Specifically, given a matrix $A(x,y)\in\K[x,y]^\mxn$ for a field $\K$
and a vector $b(x,y)\in\K[x,y]^\mx1$, we show how to describe all of
the solutions $x \in \K^\nx1$ to all of the systems
$\{ A(\alpha, \beta)x = b(\alpha, \beta):\; \alpha,\beta\in\K\}$ 
by means of a list of regimes which is of polynomial size in $m$, $n$,
and $d$, where $d$ is any upper bound on the degrees in $x$ and $y$ of the entries in 
$A, b$.
  
Our approach is to compute a Smith form of $A(x,y)$ viewed as a matrix
over the Euclidean domain $\K(y)[x]$.  This gives a sequence of
general solutions defined by the Smith form entries, which however are
subject to finitely many exceptions described by a condition 
$f(y) = 0$ for an $f\in\K[y]$.  We then show how to carry out Smith form
computations in $(\K[y]/f(y))[x]$ to solve the exceptional cases.  
The computation for the exceptional cases is 
polynomially bounded because $\deg(f)$ is. 

We remark that the one parameter case is solved by a single Smith form
computation.  
Also, by extension of this method the general $t$-parameter problem can be solved in 
time which is polynomial in the matrix size and in the degree of the entries,
being exponential only in the number of parameters (work in preparation).
Of course, as shown in the section above, a method which is also polynomial 
in the number of parameters cannot be expected. 

% I'm not completely happy with this paragraph! It sounds too
% ``competitive'' to me, but we do have to make the comparison.
%% Mark, I've tried to address your concern about that.  Whatdya think?
The techniques we employ are similar in some respects to the
Constructible Dynamic Closure methods of \cite{Duv} and
explored for triangularizing systems in \cite{Gom}.  We similarly propose 
to exploit 
a "lazy factorization" approach to the computations in an algebraic 
extension.  By using a
diagonal form rather a triangular form, and by maintaining a
correspondence between the algorithm, the rank of the localized system
and the determinantal varieties, we are able to expose the structure
required by Sit.  Our proof that the cost of the
computation is polynomial in the input size for a fixed number of
parameters does not depend on the approach taken to the algebraic extensions,
however, since the polynomial defining the algebraic extension here can 
in principle be factored in polynomial time and the subsequent computations be 
performed with respect to each irreducible factor.

\begin{theorem}
Algorithm \StPLS computes a complete set of solution regimes for the linear
system $Au = b$.  
The algorithm runs in expected time which is a polynomial in the matrix size $n$
and a bound $d$ for the degree of the entries in the parameters $x$ and $y$.
\end{theorem}

Proof sketch:
It is evident that a complete set of solution regimes is produced, 
because the semi-algebraic sets on which the Smith forms are computed form 
a partition of $K\times K$.  And for each of these semi-algebraic sets, 
the semi-algebraic subsets which are dealt with in each Smith form 
by the algorithm RegimesFromSmithForm are a partition of the given set.

Denominators arise only in steps in which a gcd is computed, 
not in steps in which a multiple of one polynomial is subtracted 
from another to obtain zero (bds: explain this more).  
After the randomization there will likely be exactly one such 
non-trivial gcd performed per step of the Hermite form computation.  

Alternatively, the denominators that arise can be seen as coming 
from the LU factorization of a large matrix \cite{Vil,Lab}.  
The entries in this matrix are coefficients of the entries in $A$, 
seen as polynomials in $u$.  Thus the entries in the large matrix 
are polynomials in $u$ of degree bounded by $d$.  
The size of the large matrix is a polynomial in $n$ and $d$, 
thus the minors, and hence the denominators in the LU factorization 
of this large matrix are of polynomial degree in $n$ and $d$.  
Furthermore there are polynomially many of them.  
Thus the least common multiple of the denominators has polynomial degree.

\newpage
\section{The algorithm}
\Line
\begin{center} $\RR \leftarrow~ $ \StPLS$(A, b, K, x, y) $ \end{center}

Input:
$A$ is an $\nxn$ matrix and $b$ is a $n$-vector both over $\K[x,y]$.
$\K$ is a field and $x$ and $y$ are parameters.  

Output:
$\RR$ is a complete set of solution regimes for the linear system $Ax = b$.
Each regime consists of a semi-algebraic set descriptor, a particular solution $x_0$, 
and a (right) null space basis for $A$.  These vectors are expressed in terms 
of the parameters and are valid on the given semi-algebraic set.
\Line

\begin{enumerate}
\item
\begin{enumerate}
\item
$(S, U, V) \leftarrow $ SmithNormalForm($A, \F[x]$),
where $\F = \K(y)$, the field of rational functions in $y$.\\[0.2cm] 
\bc
Here $A=USV$ where $S = \diag(s_1, \ldots, s_n)$ is the Smith form of $A$ over the Euclidean domain $\F[x]$.
$U$ and $V$ are unimodular matrices over $\F[x]$.  Without loss of generality, we assume and that 
$\det(U) = \det(V) = 1$, 
and that $s_1$ through $s_{n-1}$ 
are primitive.  By primitive we mean that as polynomials in $x$ they have coefficients of which are polynomials in $y$ with no common
factor.  Then any factor $c(y)$ of det($A$) which is purely a polynomial in $y$ occurs in $s_n$
(and only in $s_n$).
\ec
\item
$f(y) \leftarrow {\rm ~the~least~common~multiple~of~the~square~free~parts~of~the~denominators~in~}
U \und V.$\\[0.2cm]
\bc As polynomials in $x$, the entries in $U$ and $V$ have coefficients which
are rational in $y$.  The denominators referred to are of these coefficients. 
This $f$ contains exactly once each irreducible factor of any denominator in $U$ and $V$. Note that 
the Smith form $S$ is equivalent to $A$ for all values ($x_0, y_0$) of the parameters in which $y_0$ is not a root of $f$. \ec

\item 
$\RR_1 \leftarrow$ RegimesFromSmithForm($S, Ub, V, \{f(y) \neq 0\}$).
\end{enumerate}

\item
\begin{enumerate}
\item
$(S', U', V') \leftarrow $ SmithNormalForm($A, \F'[x]$),
where $\F' = \K[y]/(f)$.\\[0.2cm]
\bc $\F'$ is not a field but is the direct product of the fields $K[y]/(f_i)$, 
where $f_i$ are the irreducible factors of $f$.  Smith Forms are well defined in $\F'[x]$ and may often
be computed without any factorization of $f$.  Furthermore, when zero divisors turn up during the course of the
Smith Form computation, they expose a partial factorization of $f$ which may then be exploited.  Thus no explicit
factorization is needed, and in general less work will result this way than if a Smith form is computed for each 
irreducible factor of $f$. \ec

\item
$\RR_2 \leftarrow$ RegimesFromSmithForm($S', U'b, V', \{f(y) = 0\}$).
\end{enumerate}
\item
Return Simplify($\RR_1 \cup \RR_2)$.\\
\bc
The simplification alluded to here is the unification of certain regimes that
may be possible.  For example, all rank $n$ regimes can be unified because 
the condition on the denominators of $U$ and $V$ cannot be critical for these.
One has the solution regime $\{\det(A) \neq 0\}\implies (A^{-1}b)$.  For other 
ranks solutions may or may not be unifiable.  We do not explore this issue 
further here. \ec
\end{enumerate}

\newpage
The Smith form in step 1 above may be computed by any desired method.  We are able to 
prove that the denominators which arise in the unimodular cofactors $U$ and $V$ will
have polynomially bounded degree if the following Las Vegas algorithm is used, or if 
Villard's subresultant algorithm \cite{Vil,Lab} is adapted.

\Line
\begin{center}
$(S, U, V) \leftarrow $ SmithNormalForm($A, \F[x]$).\\
\bc Gives the Smith form $S$ and unimodular transforms $U$ and $V$ so that $S = UAV$. \ec
\end{center}
\Line
\begin{enumerate}
\item
Choose $r_1, \ldots, r_{n-1} \und l_1, \ldots, l_{n-1}$ at random uniformly
from a finite subset $G$ of $\F$.\\
Compute  $ A' = RAL$, where
\[ R = 
\left[ \begin{array}{ccccc}
1      & r_1    & r_2    & \cdots & r_{n-1}\\
0      & 1      & r_1    & \ddots & r_{n-2}\\
0      & 0      & 1      & \ddots & r_{n-3}\\
\vdots & \ddots & \ddots & \ddots & \vdots \\
0      & 0      & 0      & \cdots & 1      \\
\end{array}\right],
\und
L = 
\left[ \begin{array}{ccccc}
1       & 0       & 0       & \cdots & 0      \\
l_1     & 1       & 0       & \ddots & 0      \\
l_2     & l_1     & 1       & \ddots & 0      \\
\vdots  & \ddots  & \ddots  & \ddots & \vdots \\
l_{n-1} & l_{n-2} & l_{n-3} & \cdots & 1      \\
\end{array}\right]. \]
\item
Compute $H$, the Hermite form of $A'$ by the method of Kannan and Bachem 
(Chou and Collins or Storjohann's variant, say).
and the unique univariate transform matrix $U'$ associated with it.  Thus $H = U'A'$. 
With high probability, because of the random preconditioning, only one "true'' gcd computation
per diagonal entry will be computed, the remaining steps being subtraction of multiples of the 
gcd so obtained from other entries.
\item
Reduce the off-diagonal entries in each row to zero by subtracting a multiple of the diagonal
entry.  That is, reduce to the Smith form with a unit upper triangular transform V' 
operating on the right, $S = HV'$.  If this is not possible, that is, if some 
off-diagonal entry is not a multiple of the
diagonal entry in it's row, then the randomization has failed, go back to step 1.
\item
Return $S \und U := U'R \und V := LV'$.
\end{enumerate}

\newpage
Next we have the subalgorithm for extracting the regimes, each of a distinct
rank, which are directly derivable from a given Smith form.
The basic idea is that there may be a rank $i-1$ regime for each index $i$.
The $i$-th regime has the $i-1$-st invariant factor non-zero and the $i$-th
and higher invariant factors zero.  
For the linear equation system to be consistent, 
the $i$-th through the $n$-th entries of the right hand side must also be zero. 

\Line
\begin{center}
$\RR \leftarrow$ RegimesFromSmithForm($S, b, V, \alg$).\\
\bc Gives all solution regimes to $SVx = b$ on the semi-algebraic set $\alg$.\ec
\end{center}
\Line
\begin{enumerate}
\item
Let $r$ be the greatest index, $i$, such that $s_i \neq 0$.\\ 
For $i = 1$ to $r$, let $s'_i = \sqfr(s_i)$.\\
$[\sqfr(f(x))$ denotes the square free part of $f$.  It contains each 
irreducible factor of $f$ exactly once. \ec  \\
Let $d_i = s'_i$ and, for $i = 2$ to $n$, $d_i = s'_i/s'_{i-1}$.\\
\bc Thus $d_i$ is the product of those
irreducible factors of the elementary divisors that are introduced for 
the first time in the $i$-th invariant factor. \ec \\
Let $(i_1, \ldots, i_k)$ be the sequence of indices for which $d_i \neq 1$.

\item \bc Setup to start with the lowest rank case.\ec\\
Let $\alg \leftarrow \alg 
  \cup \{d_{i_1} = 0, \ldots, d_{i_k} = 0\} 
  \cup \{b_1 = 0, \ldots, b_n = 0\}$.\\
Let $y \leftarrow 0 \in \F^n$.\\
Let Regimes $\leftarrow$ \{\}.\\
\item
\bc Proceed through the ranks. \ec\\
For $i = 1$ to $r$ do\\
\jog if $d_i \neq 1$ then\\
\jogg \bc Give rank $i-1$ solution.\ec\\
\jogg particularSolution $\leftarrow Vy$.\\
\jogg nullSpaceBasis $\leftarrow (V_{*,i}, \ldots, V_{*,n})$ \bc columns of V\ec.\\
\jogg Regimes $\leftarrow$ Regimes $\cup$ regime($\alg \cup \{d_i = 0 \}\implies 
                                                   $(particularSolution, 
                                                   nullSpaceBasis)). \\
\jogg \bc Set up for next solution.\ec\\
\jogg $\alg \leftarrow \alg \cup \{d_i \neq 0\} \setminus \{b_i = 0 \}$. \\
\jogg $y_i \leftarrow b_i / s_i$\\
\jog else \bc $d_i = 1$ \ec\\
\jogg $\alg \leftarrow \alg \setminus \{b_i = 0 \}$. \\
\jogg $y_i \leftarrow b_i / s_i$\\
\item
\bc Include rank $r$ regime and done.\ec\\
Regimes $\leftarrow$ Regimes 
              $\cup$ regime($\alg \implies (Vy, V_{*,r+1}, \ldots, V_{*,n})$).\\
Return Regimes.
\end{enumerate}
\newpage
\section{Worked example}
We apply the algorithm to the problem introduced in the first section.
The first step called for by the algorithm is to compute the Smith form of the 
matrix, viewing the entries as polynomials in one of the parameters, say $x$, over the field
of rational functions in the other parameter, $\K(y)$.  

If we begin without the randomization proposed as the first step of the first Smith form
computation, we get the following.
%Actually, to get the polynomial
%bound on the number of exceptional cases, the algorithm calls for first doing a random 
%preconditioning, which we forgo in this example.  We obtain


\[
S =  
\left [\begin {array}{ccc} 
1&0&0 \\\noalign{\medskip}
0&1&0 \\\noalign{\medskip}
0&0&1-3\,yx+{x}^{3}+{y}^{3}\end {array}\right ] 
= 
\]\[
\begin{array}{cccc}
~ & U & A & V\\\noalign{\medskip}
= &
\left [\begin {array}{ccc} 
0&1/y&0\\\noalign{\medskip}
{\frac {y}{-1+{y}^{3}}}&-{\frac {1+yx}{-1+{y}^{3}}}&{\frac {{y}^{2}}{-1+{y}^{3}}}\\\noalign{\medskip}
{y}^{2}-x&-y+{x}^{2}&1-yx\end {array}\right ]
&
\left [\begin {array}{ccc} 
1&x&y\\\noalign{\medskip}
y&1&x\\\noalign{\medskip}
x&y&1\end {array}\right ]
&
\left [\begin {array}{ccc} 1&-1/y&-{\frac {{y}^{2}x-2\,y+{x}^{2}}{
-1+{y}^{3}}}\\\noalign{\medskip}0&1&{\frac {x-2\,{y}^{2}+y{x}^{2}}{-1+{
y}^{3}}}\\\noalign{\medskip}0&0&1\end {array}\right ]
\end{array}.
\]

Denominators $y$ and $y^3 - 1$ have turned up.  It happens that the denominator $y^3 - 1$ is 
fundamental to the matrix whereas $y$ is an artifact of the particular elimination taken.
The following Smith Form computation, preceeded by a randomization, eliminates the need
to consider $y = 0$ as a special case. We start with the randomization.

\[
\begin{array}{ccccc}
A' & ~ & R & A & L\\\noalign{\medskip}
\left [\begin {array}{ccc} 
1+x+y&x+y&y\\\noalign{\medskip}
1+x+y&1+x&x\\\noalign{\medskip}
1+x+y&1+y&1\end {array}\right ]
& = & 
\left [\begin {array}{ccc} 
1&0&0\\\noalign{\medskip}
0&1&0\\\noalign{\medskip}
0&0&1\end {array}\right ]
&
\left [\begin {array}{ccc} 
1&x&y\\\noalign{\medskip}
y&1&x\\\noalign{\medskip}
x&y&1\end {array}\right ]
&
\left [\begin {array}{ccc} 
1&0&0\\\noalign{\medskip}
1&1&0\\\noalign{\medskip}
1&1&1\end {array}\right ]
\end{array}.
\]
 
Then the Smith form computation follows with these unimodular cofactors 
(which include the $R$ and $L$).

\[
S = 
\left [\begin {array}{ccc} 
1&0&0\\\noalign{\medskip}
0&1&0\\\noalign{\medskip}
0&0&{y}^{3}-3\,yx+{x}^{3}+1\end {array}\right ] =
\]\[
\begin{array}{cccc}
U & A & V\\\noalign{\medskip}
\left [\begin {array}{ccc} 
0&0&1\\\noalign{\medskip}
{\frac {-y}{-1+{y}^{3}}}&{\frac {-1}{-1+{y}^{3}}}&{\frac {x+{y}^{2}}{-1+{y}^{3}}}\\\noalign{\medskip}
-yx+1&{y}^{2}-x&{x}^{2}-y\end {array}\right ]
&
\left [\begin {array}{ccc} 
1+x+y&x+y&y\\\noalign{\medskip}
1+x+y&1+x&x\\\noalign{\medskip}
1+x+y&1+y&1\end {array}\right ]
&
\left [\begin {array}{ccc} 0&0&1\\\noalign{\medskip}0&1&-{\frac {{x}^{2
}+x{y}^{2}-2\,y}{-1+{y}^{3}}}\\\noalign{\medskip}1&-y&{\frac {x+{x}^{2}
y-2\,{y}^{2}}{-1+{y}^{3}}}\end {array}\right ]
\end{array}.
\]
\newpage
The exceptional cases thus are limited to parameter values for which ${y}^{3} - 1 = 0$.
Before turning to them, we compute regimes in which ${y}^{3} - 1 \neq 0$.
There are 2, the full rank one and that for which the determinant is zero.

The right hand side is $Ub$, for solving $Sv = Ub$.
\[
\left [\begin {array}{c} 1\\\noalign{\medskip}
{\frac {-y-1+x+y^2}{-1+{y}^{3}}}\\\noalign{\medskip}
-yx+1+{y}^{2}-x+{x}^{2}-y\end {array}\right ]
= Ub =
\left [\begin {array}{ccc} 
0&0&1\\\noalign{\medskip}
{\frac {-y}{-1+{y}^{3}}}&{\frac {-1}{-1+{y}^{3}}}&{\frac {x+{y}^{2}}{-1+{y}^{3}}}\\\noalign{\medskip}
-yx+1&{y}^{2}-x&{x}^{2}-y\end {array}\right ]
\left [\begin {array}{c} 1\\\noalign{\medskip}1\\\noalign{\medskip}1
\end {array}\right ]
\]

Multiplying by $S^{-1}$ and then mapping with $V$ to obtain a solution to the
original system,  we obtain a first solution regime

%%%%????
%                     3            3                 3
%            R1 := [{y  - 3 y x + x  + 1 <> 0, -1 + y  <> 0}, {u1}]

\[\RR1 =  
\breg {y}^{3}-3\,yx+{x}^{3}+1\neq 0//-1+{y}^{3}\neq 0\ereg \implies
(
%{\it u1}
\left [\begin {array}{c}1/ \left (1+x+y\right )\\\noalign{\medskip}
1/ \left (1+x+y\right )\\\noalign{\medskip}
1/ \left (1+x+y\right )
\end {array}\right ]
).
\]

The condition that the determinant is not zero implies that 
$1 + x + y$ is not zero, because it is a factor of the determinant,

\[
{y}^{3}-3\,xy+{x}^{3}+1 = 
(1 + x + y) (x^2  - x - x y - y + 1 + y^2 ).
\]
%                          [              1              ]
%                          [                             ]
%                          [                           2 ]
%                          [     y         1      x + y  ]
%                    v2 := [- ------- - ------- + -------]
%                          [        3         3         3]
%                          [  -1 + y    -1 + y    -1 + y ]
%                          [                             ]
%                          [              0              ]

For the second regime we have the particular solution to $Sv = Ub$,  
\[v = 
\left [\begin {array}{c} 1\\\noalign{\medskip}
\frac {-y-1+x+y^2}{-1+{y}^{3}}\\\noalign{\medskip}
0\end {array}\right ]
\]
and the null space is spanned by the third column of the identity matrix.
Mapping these with $V$ we get the second regime
%                                 [        0         ]
%                                 [                  ]
%                                 [               2  ]
%                                 [ -y - 1 + x + y   ]
%                                 [ ---------------  ]
%                                 [           3      ]
%                           u2 := [     -1 + y       ]
%                                 [                  ]
%                                 [       2          ]
%                                 [  1 - y  - y + y x]
%                                 [- ----------------]
%                                 [            3     ]
%                                 [      -1 + y      ]

%                                  [        1        ]
%                                  [                 ]
%                                  [   2      2      ]
%                                  [  x  + x y  - 2 y]
%                                  [- ---------------]
%                                  [            3    ]
%                           u21 := [      -1 + y     ]
%                                  [                 ]
%                                  [      2        2 ]
%                                  [ x + x  y - 2 y  ]
%                                  [ --------------- ]
%                                  [           3     ]
%                                  [     -1 + y      ]

%                    2        2           3            3
%R2 := [{-y x + 1 + y  - x + x  - y = 0, y  - 3 y x + x  + 1 = 0, 1 <> 0,
%
%          3
%    -1 + y  <> 0}, {u2, u21}]
%
\[ \RR2 = 
\breg -yx+1+{y}^{2}-x+{x}^{2}-y=0\\
-1+{y}^{3}\neq 0 \ereg \implies
%{\it u2},{\it u21}
%> latex(u2);
(\left [\begin {array}{c} 0\\\noalign{\medskip}{\frac {-y-1+x+{y}^{2}}{-
1+{y}^{3}}}\\\noalign{\medskip}-{\frac {1-{y}^{2}-y+yx}{-1+{y}^{3}}}
\end {array}\right ],
%> latex(u21);
\left [\begin {array}{c} 1\\\noalign{\medskip}-{\frac {{x}^{2}+x{y}^{2}
-2\,y}{-1+{y}^{3}}}\\\noalign{\medskip}{\frac {x+{x}^{2}y-2\,{y}^{2}}{-
1+{y}^{3}}}\end {array}\right ]
),
\]
where polynomials defining the semi-algebraic set are the consistency
condition $b'_3 = 0$ and the denominator condition.
It happens that the consisitency polynomial is a factor of the determinant, so without
loss, the determinant condition has been dropped.

Next we turn our attention to the exceptional case for the first Smith form, the case for which
the denominators, $y^3 - 1$, in the cofactor matrices are zero.  
We can do the Smith form in this case without the random preconditioning, as there
will be no denominators and all degrees in $y$ will be less than 3.  However,
our modulus, $y^3 - 1$ is not irreducible, and it may arise that there is an attempt
during the Smith form computation to invert a zero 
\newpage
divisor.  While that problem
is easily handled, it is even better if it does not arise.  A random preconditioning
might help avoid that problem.  However, in this case it proves unnecessary.
In a straghtforward way we get the Smith form:

\[
\begin{array}{ccccc}
S' & ~ & U' & A & V'\\\noalign{\medskip}

\left [\begin {array}{ccc} 1&0&0\\\noalign{\medskip}0&-{y}^{2}+x&0\\\noalign{\medskip}
0&0&{x}^{2}+x{y}^{2}-2\,y\end {array}\right ]
& = &
\left [\begin {array}{ccc} 1&0&0\\\noalign{\medskip}{y}^{3}&-{y}^{2}&0\\\noalign{\medskip}
-{y}^{3}&x+{y}^{2}&-y\end {array}\right ]
&
\left [\begin {array}{ccc} 1&x&y\\\noalign{\medskip}y&1&x\\\noalign{\medskip}
x&y&1\end {array}\right ]
&
\left [\begin {array}{ccc} 1&-x&-x{y}^{2}-y\\\noalign{\medskip}0&1&{y}^
{2}\\\noalign{\medskip}0&0&1\end {array}\right ]
\end{array}
\]

The right hand side to be considered %to solve $Sv = Ub$ is 
is
 
\[ 
\left [\begin {array}{c} 1\\\noalign{\medskip}-{y}^{2}+1\\\noalign{\medskip}
-y-1+x+{y}^{2}\end {array}\right ]
= U'b = 
\left [\begin {array}{ccc} 1&0&0\\\noalign{\medskip}{y}^{3}&-{y}^{2}&0\\\noalign{\medskip}
-{y}^{3}&x+{y}^{2}&-y\end {array}\right ]
\left [\begin {array}{c} 1\\1\\1 \end {array}\right ].
\]

%> v3 := array([[bp4[1,1]/S4[1,1]],[bp4[2,1]/S4[2,2]],[bp4[3,1]/S4[3,3]]]);
%                                  [       1       ]
%                                  [               ]
%                                  [      2        ]
%                                  [    -y  + 1    ]
%                                  [    -------    ]
%                                  [      2        ]
%                            v3 := [    -y  + x    ]
%                                  [               ]
%                                  [              2]
%                                  [-y - 1 + x + y ]
%                                  [---------------]
%                                  [ 2      2      ]
%                                  [x  + x y  - 2 y]

%> latex(v3);
%\[v3 = 
%\left [\begin {array}{c} 1\\\noalign{\medskip}{\frac {-{y}^{2}+1}{-{y}^
%{2}+x}}\\\noalign{\medskip}{\frac {-y-1+x+{y}^{2}}{{x}^{2}+x{y}^{2}-2\,
%y}}\end {array}\right ]
%\]
%u3 :=
%
%    [         3    2        2  3        2    4      2  2    5      3          2
%    [y (-2 x y  + y  + x + x  y  - 2 x y  - y  x + x  y  + y  x - y  + y x - x
%    [
%
%        4    /     2        2      2        ]
%     + y )  /  ((-y  + x) (x  + x y  - 2 y))]
%           /                                ]
%
%    [  4        3    2          5      3    4    6]
%    [-y  x + 2 y  + x  - 2 y + y  - x y  + y  - y ]
%    [---------------------------------------------]
%    [            2        2      2                ]
%    [         (-y  + x) (x  + x y  - 2 y)         ]
%
%    [              2]
%    [-y - 1 + x + y ]
%    [---------------]
%    [ 2      2      ]
%    [x  + x y  - 2 y]
%
%> latex(u3);
The rank three solution, assuming the determinant is not zero, is 
\[\RR3 = 
\breg
-1+{y}^{3}=0\\{x}^{2}+x{y}^{2}-2\,y\neq 0\ereg \implies
(
\left [\begin {array}{c} 
{\frac {-y-1+x+{y}^{2}}{{x}^{2}+x{y}^{2}-2\,y}}\\\noalign{\medskip}
{\frac {-y-1+x+{y}^{2}}{{x}^{2}+x{y}^{2}-2\,y}}\\\noalign{\medskip}
{\frac {-y-1+x+{y}^{2}}{{x}^{2}+x{y}^{2}-2\,y}}
\end {array}\right ]
).\]
When $y^3 -1 = 0$, the determinant here equals the original determinant and the vector
entries also equal those given in regime $\RR1$, namely $1/(1+x+y)$.  Thus we can
combine $\RR1 \und \RR4$ getting just regime $\RR1$ with the $y^3 -1 \neq 0$ condition removed. 

%> R3 := [{S4[3,3] <> 0, f = 0}, {u3}];
%                             3       2      2
%               R3 := [{-1 + y  = 0, x  + x y  - 2 y <> 0}, {u3}]
%
%> 
%> v4 := array([[bp4[1,1]/S4[1,1]],[bp4[2,1]/S4[2,2]],[0]]);
%                                      [   1   ]
%                                      [       ]
%                                      [  2    ]
%                                      [-y  + 1]
%                                v4 := [-------]
%                                      [  2    ]
%                                      [-y  + x]
%                                      [       ]
%                                      [   0   ]
%
%> latex(v4);
%\[v4 =
%\left [\begin {array}{c} 1\\\noalign{\medskip}{\frac {-{y}^{2}+1}{-{y}^
%{2}+x}}\\\noalign{\medskip}0\end {array}\right ]
%\]
%> u4 := map(simplify, multiply(V4, v4)); 
%                                    [ 2         ]
%                                    [y  (-1 + x)]
%                                    [-----------]
%                                    [    2      ]
%                                    [  -y  + x  ]
%                                    [           ]
%                              u4 := [    2      ]
%                                    [   y  - 1  ]
%                                    [ - ------- ]
%                                    [     2     ]
%                                    [   -y  + x ]
%                                    [           ]
%                                    [     0     ]
%
%> latex(u4);
%\[u4 = 
%\left [\begin {array}{c} {\frac {{y}^{2}\left (-1+x\right )}{-{y}^{2}+x
%}}\\\noalign{\medskip}-{\frac {{y}^{2}-1}{-{y}^{2}+x}}
%\\\noalign{\medskip}0\end {array}\right ]
%\]
%> v41 := array([[0],[0],[1]]);
%                                          [0]
%                                          [ ]
%                                   v41 := [0]
%                                          [ ]
%                                          [1]
%
%> latex(v41);
%\[v41 =
%\left [\begin {array}{c} 0\\\noalign{\medskip}0\\\noalign{\medskip}1
%\end {array}\right ]
%\]
%> u41 := map(simplify, multiply(V4, v41));
%                                      [    2    ]
%                                      [-x y  - y]
%                                      [         ]
%                               u41 := [    2    ]
%                                      [   y     ]
%                                      [         ]
%                                      [    1    ]
%
%> latex(u41);
%\[u41 =
%\left [\begin {array}{c} -x{y}^{2}-y\\\noalign{\medskip}{y}^{2}
%\\\noalign{\medskip}1\end {array}\right ]
%\]
%> R4 := [{S4[2,2] <> 0, S4[3,3] = 0, bp4[3,1] = 0, f = 0}, {u4, u41}];
%         2      2                          2        2                 3
%R4 := [{x  + x y  - 2 y = 0, -y - 1 + x + y  = 0, -y  + x <> 0, -1 + y  = 0},
%
%    {u4, u41}]
%
%> latex(R4);
Then subject to the third invariant factor being zero and the second being non-zero,
we have a fourth solution regime.
Since the second invariant factor in the Smith form divides the third, in fact we have
${x}^{2}+x{y}^{2}-2\,y = (x + 2y^2)(x-{y}^{2}),$
we are assume that the first factor is zero while the second is non-zero.  
We have also the consistency condition that $b'_3 = 0$.
 
\[\RR4 = 
\breg x + 2y^2 = 0\\ -y-1+x+{y}^{2}=0\\-{y}^{2}+x\neq 0\\-1+{y}^{3}=0\ereg \implies 
%\[u4 = 
(\left [\begin {array}{c} {\frac {{y}^{2}\left (-1+x\right )}{-{y}^{2}+x
}}\\\noalign{\medskip}-{\frac {{y}^{2}-1}{-{y}^{2}+x}}\\\noalign{\medskip}
0\end {array}\right ]
,
%\[u41 =
\left [\begin {array}{c} -x{y}^{2}-y\\\noalign{\medskip}{y}^{2}\\\noalign{\medskip}
1\end {array}\right ]
).
\]
Both the semi-algebraic set description and the vector entries can be simplified quite 
a bit under all these conditions, and we arrive at this alternative presentation of the
fourth regime,
\[\RR4a = 
\breg x + 2y^2 = 0\\ y^2 + y + 1 = 0\ereg \implies
%\[u4 = 
(\left [\begin {array}{c} 
{\frac {-y+1}{3y+3}}\\\noalign{\medskip}
{\frac {y+2}{3y+3}}\\\noalign{\medskip}
0\end {array}\right ]
,
%\[u41 =
\left [\begin {array}{c} 
y\\\noalign{\medskip}
-y-1\\\noalign{\medskip}
1\end {array}\right ]
).
\]

\newpage
Actually, as in the rank 3 case the rank 2 regimes can be combined as William Sit managed to
do with his minor based algorithm.  The merging step could be aplied here.  It is not immediately
obvious that is works.
 
%> 
%> v5 := array([[bp4[1,1]/S4[1,1]],[0],[0]]);
%                                         [1]
%                                         [ ]
%                                   v5 := [0]
%                                         [ ]
%                                         [0]
%
%> latex(v5);
%\[v5 =
%\left [\begin {array}{c} 1\\\noalign{\medskip}0\\\noalign{\medskip}0
%\end {array}\right ]
%\]
%> u5 := map(simplify, multiply(V4, v5));
%                                         [1]
%                                         [ ]
%                                   u5 := [0]
%                                         [ ]
%                                         [0]
%
%> latex(u5);
%\[u5 =
%\left [\begin {array}{c} 1\\\noalign{\medskip}0\\\noalign{\medskip}0
%\end {array}\right ]
%\]
%> v51 := array([[0],[1],[0]]);
%                                          [0]
%                                          [ ]
%                                   v51 := [1]
%                                          [ ]
%                                          [0]
%
%> latex(v51);
%\[v51 =
%\left [\begin {array}{c} 0\\\noalign{\medskip}1\\\noalign{\medskip}0
%\end {array}\right ]
%\]
%> u51 := map(simplify, multiply(V4, v51));
%                                         [-x]
%                                         [  ]
%                                  u51 := [1 ]
%                                         [  ]
%                                         [0 ]
%
%> latex(u51);
%\[u51 =
%\left [\begin {array}{c} -x\\\noalign{\medskip}1\\\noalign{\medskip}0
%\end {array}\right ]
%\]
%> v52 := array([[0],[0],[1]]);
%                                          [0]
%                                          [ ]
%                                   v52 := [0]
%                                          [ ]
%                                          [1]
%
%> latex(v52);
%\[v52 =
%\left [\begin {array}{c} 0\\\noalign{\medskip}0\\\noalign{\medskip}1
%\end {array}\right ]
%\]
%> u52 := map(simplify, multiply(V4, v52));
%                                      [    2    ]
%                                      [-x y  - y]
%                                      [         ]
%                               u52 := [    2    ]
%                                      [   y     ]
%                                      [         ]
%                                      [    1    ]
%
%> latex(u52);
%\[u52 =
%\left [\begin {array}{c} -x{y}^{2}-y\\\noalign{\medskip}{y}^{2}
%\\\noalign{\medskip}1\end {array}\right ]
%\]
%> R5 := [{S4[1,1] <> 0, S4[2,2] = 0, bp4[2,1] = 0,  S4[3,3] = 0, bp4[3,1] = 0, f = 0}, {u5, u51, u52}];
%         2      2                          2                2
%R5 := [{x  + x y  - 2 y = 0, -y - 1 + x + y  = 0, 1 <> 0, -y  + x = 0,
%
%      2                3
%    -y  + 1 = 0, -1 + y  = 0}, {u5, u51, u52}]
%
%> latex(R5);
Finally, with both invariant factors and in consideration of right hand side constraints we 
have our fifth solution regime
\[\RR5 = 
\breg -y-1+x+{y}^{2}=0\\-{y}^{2}+x=0\\-{y}^{2}+1=0\\-1+{y}^{3}=0\ereg \implies
%{\it u5}
%\[u5 =
(\left [\begin {array}{c} 1\\\noalign{\medskip}0\\\noalign{\medskip}0
\end {array}\right ]
,%{\it u51}
%\[u51 =
\left [\begin {array}{c} -x\\\noalign{\medskip}1\\\noalign{\medskip}0
\end {array}\right ]
,%{\it u52}
%\[u52 =
\left [\begin {array}{c} -x{y}^{2}-y\\\noalign{\medskip}{y}^{2}\\\noalign{\medskip}
1\end {array}\right ]
).
\]

This regime also simplifies quite substantially until we see the form we already observed
by inspection at the first look at the problem.  It is

\[\RR5a = 
\breg y-1 = 0\\x-1 = 0\ereg \implies
%{\it u5}
%\[u5 =
(\left [\begin {array}{c} 1\\\noalign{\medskip}0\\\noalign{\medskip}0
\end {array}\right ]
,%{\it u51}
%\[u51 =
\left [\begin {array}{c} -1\\\noalign{\medskip}1\\\noalign{\medskip}0
\end {array}\right ]
,%{\it u52}
%\[u52 =
\left [\begin {array}{c} -2\\\noalign{\medskip}1\\\noalign{\medskip}
1\end {array}\right ]
).
\]

\section{Conclusion}
We have presented an algorithm based on Smith form computations which solves bivariate
parametric linear systems in polynomial time.  Though reasonable tractability of this 
problem is thus established, from a small sample computation we have 
seen that it will be very desirable and important to simplify and merge the solution 
regimes whenever possible.
This indicates that there is very much potential for work to find improved practical 
algorithms for this problem.

\begin{thebibliography}{fourr}

\bibitem{Duv} 
D. Duval,
\newblock  Diverses questions relatives au calcul formel avec des nombres algebriques.
\newblock These d'Etat, Universite de Grenoble 1 
\newblock (1987).

\bibitem{Gom}
T. Gomez-Diaz,
\newblock Quelque applications de l'\'evaluation dynamic,
\newblock Ph.D. Thesis: Universit\'e de Limoges,
\newblock (1992).

\bibitem{Lab}
S.E. Labhalla, H. Lombardi, R. Marlin,
\newblock Algorithmes de calcul de la r\'eduction d'Hermite d'une matrice \`a coefficients polynomiaux,
\newblock {\em Theoretical Computer Science}, (1996), {\bf 161}, 69-92.

\bibitem{MaMe}
E. Mayr, A. Meyer,
\newblock The complexity of the word problems for commutative semigroups and polynomial ideals,
\newblock {\em Adv. in Math.}, (1982), {\bf 46}, 305--329. 

\bibitem{Sit}
William Sit,
\newblock Parametric linear systems,
\newblock {\em J. Symbolic Computation}, (1992), {\bf 13}, 353-394.

\bibitem{Vil}
Gilles Villard,
\newblock Generalized subresultants for computing the Smith normal form of polynomial matrices,
\newblock {\em J. Symbolic Computation}, (1995), {\bf 20}, 269-286.


\end{thebibliography}

\bibliographystyle{alpha}
\end{document}




