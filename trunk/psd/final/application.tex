\section {Application to Lie matrices}
The matrices from Lie group representation are rational matrices.
Our algorithms in the previous section focus on integer matrices.
There are at least two ways to adapt.
One is to compute the minimal polynomial, or the leading principal minors
over the rationals.
Rational numbers must be reconstructed at the GenCRA,
and it is easy to adopt our GenCRA, including the early termination technique,
to this case.
The other way is to multiply the matrices by the $\lcm$ of
the denominators of all entries.
For these specially constructed matrices from Lie group representation, 
the $\lcm$ of the denominators of all entries
is just a little larger than each individual one,
so this latter way is a better.
We found for some models that the $\gcd$ of all the
numerators in the dense representation is not trivial and  can be removed.

Next we present blackbox algorithms to compute the
$\lcm$ of denominators of all entries, 
and $\gcd$ of numerators of all entries,
respectively.
\begin{algorithm} {LD [LCM of Denominators]}
\Inspec \\
$A$, a rational matrix\\
$M$, sample size\\
$n$, number of trials
\Outspec \\
$d$, the $\lcm$ of denominators of all entries of dense representation of $A$.
\Stmt[1.]
for $i$ from $1$ to $n$ do\\
Choose a random vector $x^{(i)}$ with entries independently and uniformly chosen
from $[0, M-1]$\\
$y^{(i)} = A x^{(i)}$, apply $x^{(i)}$ to $A$\\
$d^{(i)}$= the $\lcm$ of denominators of every entry of $y^{(i)}$.
\Stmt[2.]
$d := \lcm (d^{(1)}, \cdots, d^{(i)})$
\Stmt[3.]
return $d$.
\end{algorithm}

\begin{algorithm}{GN [Gcd of Numerators]}
%\Inspec \\
%$A$, an integer matrix\\
%$M$, sample size\\
%$n$, number of trials
%\Outspec \\
%$g$, the $\gcd$ of all entries of dense representation of $A$.
%\Procspec\\
\\Apply algorithm {\em LD} by replacing $\lcm$ with $\gcd$ and 
denominators with numerators.
\end{algorithm}

The algorithm {\em LD}
always returns a factor of the true answer.
The algorithm {\em GN}
always returns a multiple of the true answer.
For a rational matrix $A$, if 
$d$ and $g$ are the $\lcm$ of all denominators 
and $\gcd$ all numerators of entries of $A$, respectively,
then If $A^\prime = \frac{d}{g}A$ is an integer matrix.
For each individual trial,
if all entries of  $A^\prime x^{(i)}$ are coprime,
then $d^{(i)}$ is correct in both algorithms.
Please see \cite{Saunders::LA::2004} for probability analysis. 
Roughly speaking, the error probability is $2^{-n + 1}$.

Each matrix $J_\rho(\nu)$ in equation 3 can be represented as
a product of many sums of sparse matrices and scalar matrices.
%%$[\prod \frac1{r_i}(r_iT_i +I)]J_\rho$, where $T_i=\rho(s_{\alpha_i})$
%as in Section 2.
%%, and $T_i$ and $J_\rho$ are sparse matrices.
The algorithm BBSM is very suitable for this case.
We also reduce the product of $121$ sums of sparse matrices and scalar matrices
to a product of $94$ sparse matrices for the $E_8$ case. 
We explicitly compute each sum of a sparse matrix and a scalar matrix and 
store them as a single sparse matrix.  Also, if the result is a diagonal matrix,
explicitly multiply it into the previous factor.
By reducing the number of sparse matrices in this way, 
$20\%$ run time was saved for the BBSM algorithm. 
After multiplying these collapsed matrices 
by the $\lcm$ of denominators of all entries and dividing
by $\gcd$ of numerators, these matrices can be handled by the
algorithms discussed in the previous section.
