\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}
\usepackage{calc,listings,color}

\usepackage[ruled,nothing]{algorithm}
\usepackage{algorithmic}
\renewcommand{\algorithmicrequire}{{\textbf{Input:}}}
\renewcommand{\algorithmicensure}{{\textbf{Output:}}}

\usepackage{url,xspace}

\newcommand{\linboxsp}{{\sc LinBox}\xspace}
\newcommand{\linbox}{{\sc LinBox}}

\begin{document}

\mainmatter  
\title{\linboxsp memory management and parallel model}
%\titlerunning{}
\author{The \linboxsp group}
\maketitle

\section{Introduction}

As a building block for a wide range of applications, computational exact linear
algebra has to conciliate both efficiency and genericty. The goal of the 
\linboxsp project is to address this problem by designing an efficient general-purpose
\texttt{C++} open-source library for exact linear algebra over the integers, the
rationals and finite fields. 
Matrices can be either dense, sparse or black box (i.e. viewed as a linear
operator, acting on vectors only). The library proposes a set of high level
linear algebra solutions, such as the rank, the determinant, the solution of a
linear system, the smith normal form, the echelon form, the characteristic
polynomial, ... Each of these solutions involve a hybrid combination of several specialized
algorithms depending on the domain, and the type of matrix. Over a finite field,
the building blocks are an efficient implementation of Wiedemann and block
Wiedemann algorithms combined with preconditioners~\cite{CEKSTV:2002:EP} for
black box matrices, a sparse Gaussian elimination for sparse matrices and the
BLAS based dense linear algebra techniques of the \texttt{FFLAS}
library~\cite{DGP:2008:dlaff} for dense matrices. The solutions over the integers
and rationals are lifted from modular computations by a Chinese remainder
algorithm or $p$-adic lifting.
The design based on a high genericity allow to write efficient algorithms  independently from the
representations of domains and matrices. As a middleware, the library relies on the
efficiency of kernel libraries such as  \texttt{GMP}\footnote{\url{http://gmplib.org/}},
\texttt{Givaro}\footnote{\url{http://www-ljk.imag.fr/CASYS/LOGICIELS/givaro/}},
\texttt{NTL}\footnote{\url{http://www.shoup.net/ntl/}},
\texttt{ATLAS}\footnote{\url{http://math-atlas.sourceforge.net/}} and can be used by general
purpose computer algebra systems such as \texttt{Sage}\footnote{\url{http://sagemath.org/}} or \texttt{Maple}\footnote{\url{http://www.maplesoft.com/}}. 

\section{A lightweight memory management}

\subsection{Call-by-reference}

Only references as argument (no value returned), first args as return
values.

\verb! Matrix & Function( Matrix & result, const XXX& args); !

example of fields \cite[\S 2.1]{jgd:2002:icms} ?

\subsection{The mother model}


The mother model: functions should not allocate their return values

\begin{itemize}
\item more efficient: allocations are limited

\item requires more involvment by the programmer: control of the allocation

\item garbage collection is simplified: reference counting with a single
boolean, or even better (sic) by two different classes.
Especially for thread-safety.
\end{itemize}


\subsection{Rebind of matrices}

mecanism of the rebind for fields adapted from STL rebind of
allocators.

Since rebind must not allocate, only references are given (re)
allocation is done by the caller (and not rebind), rebind only maps
values from one field to another.

\begin{itemize}
\item generic homomorphism 
\verb!e.init( newelt, e.convert( Integer, oldelt) )!
can be specialized.
\end{itemize}

\section{Abstraction of a level for parallelism}


Efficient parallel applications must take into consideration of hardware characteristics (number of cores, memory hiearchy, ...): it time consuming or impossible for a single developer to be able to program a high performance computer algebra application, with state of the art algorithm, that will exploit all the available parallelism. 
In order to separate the domain of expertise we have design an software abstraction layer between computer algebra algorithm and parallel implementation with automatic dynamic scheduling.

\subsection{Parallel building blocks}
Computer algebra algorithms have three main characteristics: 1/ they are complex, a deep knowledge about the problem is required to be able to write the most efficient sequential algorithm; 2/ they may be highly irregular which impose the use, at runtime, of algorithms to balance the work load; 3/ they are generic in the sens that its easy to write a generic algorithm that will work with several input domain.

  In the case of LinBox algorithms, we have decided to base our software abstraction, called Parallel Building Blocks (PBB), close to principle of STL (Standard Template Like) algorithms. C++ data structure in Linbox let us to have random access iterators over container which are easy to parallelism. Currently with have only defined few algorithms and the list may be extended in the futur:
\begin{description} 
\item [for\_each, transform, accumulate]: they are similar to the STL version except that involved operators (or function class) are required to have their return value passed by the first parameter of the function. This is mainly due because in LinBox,  objects returned by operator may have big size (\textit{e.g} a matrix) and the STL return-by-value semantic is not appropriate. 
\end{description} 
Note that within the incoming C++0X standard, the lambda capability of the core language will simplify the use of these parallel building blocks in true code.

%\verb!transform!, etc. 

%\begin{itemize}
%\item Transparent parallelism
%\item Abstraction of parallelism
%\item Parallelism really as a plug-in
%\end{itemize}
The most important thing is that these algorithms may be easily parallelism on top of Open MP, %~\cite{}, 
TBB (Thread Building Blocks)%~\cite{} 
or Kaapi~\cite{inproceedingsgautier.gbp_ktsrsf_07} middleware, using both static scheduling or dynamic work-stealing algorithm~\cite{con-traore.trmgb_08}.
The current implementation support OpenMP and Kaapi.

\subsection{Accumulate-while and early termination}
  To bound the complexity of some linear algebra problems,  one of the key algorithm is to use Chinese Remaindering algorithm. The computation is done modulo a sequence of (co)prime numbers and the result is built from a sequence of residues while a condition is not satisfy~\cite{jgd:2010:crt}. The termination of the algorithm depend on the result remaindered for each residue. 
  In order to capture such algorithm we proposed an extension of the STL algorithms called \verb+accumulate_while+:
\begin{description} 
\item [accumulate\_while]: for a sequence of length $n$, the algorithm computes $S_N = \sum_{i=0,..,N} f(input[i])$ such that $S_k, k>N$ does not satisfy a condition and  $S_k, k \leq N$ may satisfy a condition. The algorithm takes as input $input$, $f$, $+$ operator for the summation and it returns $S_N$ and $N$. This algorithm is used for early termination algorithm such as illustrated above.
\end{description} 

%\verb!Accumulate-while!, generalization of \cite{jgd:2010:crt},
%specially adapted to early termination in mathematical softwares.
%Other applications (e.g. from \cite{Beaumont:2004:PMAA}) ??


\subsection{Memory contention}
Most of computer algebra programs allocate dynamic memory for the intermediate computation.
Several experiments with Linbox algorithms on multicore machine have shown that allocations are a bottleneck in the performance. 
  An analysis of memory pattern and experimentation with 3 well known memory allocators  (ptmalloc, Hoard and TCMalloc from Google Perf Tools) have been done. Preliminary experiments on problems which are based on top of Chinese Remaindering~\cite{jgd:2010:crt} have demonstrate the advantage of TCMalloc~\cite{tcmalloc} over the others. 
  One of the main reason is that such problems made a lot of temporary allocations that fit well the thread safe caching mechanism of TCMalloc.

\section{Automated Generic Separate compilation}
\linboxsp is developped with several levels of genericity:
\begin{itemize}
\item Genericity with respect to the domain of the coefficients;
\item Genericity with respect to the data structure of the matrices;
\item Genericity with the intermediate algorithms;
\item ...
\end{itemize}
While efficient in terms of capabilities and code reusability, this
can lengthen the compilation time and generate large executable files.\\
For the management of code bloat \linboxsp proposes an ``archetype
mecanism'' which enable, at the user latitude, to switch to a
compilation against abstract classes \cite[\S 2.1]{jgd:2002:icms}.\\
This can reduce the efficiency of the library. Therefore, we propose
here a way to provide a generic separate compilation. This will not
deal with code bloat, but will reduce the compilation time while
preserving the performances.\\
This is useful for instance when the library is used with
unspecialized calls. This is largely the case for some interface
wrappers to other Computer algebra systems such as {\sc Sage} or {\sc Maple}.\\
Our idea is to automatize the technique of
\cite{Erlingsson:1996:issac} which combines compile-time instantiation
and link-time instantiation, while using template instantiation
instead of void pointers.\\
The mecanism we propose is independent of the desired method, candidate
for separate compilation and is explained on algorithm \ref{alg:sep}.
\begin{algorithm}[ht]
\caption{C++ Automatic separate compilation wrapping}\label{alg:sep}
\begin{algorithmic}[1]
\REQUIRE A generic function \texttt{func}.
\REQUIRE Some template parameters for separate specialization and
compilation of  \texttt{func}.
\ENSURE A generic function calling
\texttt{func} with separately compiled instantiations.
\STATE Create a header and a body files ``func\_instantiate.hpp'' and ``func\_instantiate.cpp'';
\STATE Add a template function \texttt{func\_separate}, with the same
specification as \texttt{func}, to the header;
\STATE Its generic default implementation is a single line calling the
original function \texttt{func}.\\ \COMMENT{This enables to have a
  unified interface, even for non specialized class.}
\FOR{each separately compiled template parameter \texttt{TParam}}
  \STATE Add  a non template specification
  \texttt{funcTParam}, to the header file;
  \STATE Add the associated body with a
  single line returning the instantiation of
  \texttt{func} on a parameter of type \texttt{TParam}, to the body file;
  \STATE Add an inline specialization
  body of \texttt{func\_separate} on a parameter of type
  \texttt{TParam} with a single line returning \texttt{funcTParam}, to
  the header file; 
\ENDFOR
\STATE Compile the body file ``func\_instantiate.cpp''.
\end{algorithmic}
\end{algorithm}

This Algorithm is illustrated on figure \ref{fig:sep}, where
the function is the \texttt{rank} and the template parameter is a dense
matrix over the finite field with two elements,
\texttt{DenseMatrix<GF2>}.
\begin{figure}[ht]
\includegraphics[width=\textwidth]{separate}
\caption{Separate compilation of a rank specialization}\label{fig:sep}
\end{figure}

We show on table \ref{tab:compilation} the gains, in term of compilation time,
obtained on two examples of \linbox: the \texttt{examples/rank.C} and
\texttt{examples/solve.C} algorithms. Indeed without any specification
the code
has to be generic and to invoke several specializations depending on
run-time discovered properties of thei input. For instance the
\texttt{solve.C} example requires at least 6 specializations for sparse
matrices over the Integers or over a prime field, with a sparse
elimination, or an iterative method, or a dense method if the matrix
is small, or an hybrid method...\\ 
\begin{table}[ht]\center
\begin{tabular}{|l||r|r|r||r|r|r|}
\hline
file                      &  real time   &  user time   &  sys. time  &  real time   &  user time   &  sys. time \\
\hline
 & \multicolumn{3}{|c||}{Rank}& \multicolumn{3}{|c|}{Solve}\\
\hline
\texttt{instantiate.o} & 143.43s & 142.47s & 0.90s & 171.62s & 170.42s & 1.12s\\
\texttt{separate.o} & \bf 18.58s & \bf 18.26s & \bf 0.30s & \bf 23.13s & \bf 22.80s & \bf 0.32s\\
\texttt{separate} & 0.80s & 0.64s & 0.15s & 0.85s & 0.70s & 0.14s\\
\hline
\texttt{Sep. comp.} & 162.81s & 161.37s & 1.35s & 195.60s & 193.92s & 1.58s\\
\hline
\texttt{Full comp.} & 162.02s & 160.47s & 1.21s & 191.47s & 189.52s & 1.40s\\
\hline
\hline
\texttt{speed-up} & 8.4 & 8.5 & 2.7 & 8.0 & 8.1 & 3.0s\\
\hline
\end{tabular} 
\caption{linbox/examples/\{rank,solve\}.C compilation time on an AMD
  Athlon 3600+, 1.9GHz, with gcc 4.5 -O2. \texttt{instantiate.o} corresponds to the separately compiled
  instantiatiations (e.g. densegf2rank in figure \ref{fig:sep});
  \texttt{separate.o} corresponds to the user interface and generic
  implementation compilation; \texttt{separate} corresponds to the
  linking of both \texttt{.o} and the library.}\label{tab:compilation}
\end{table}

\begin{remark} Algorithm \ref{alg:sep} has been simplified for the
  sake of clarity. To enable a more user-friendly interface and to
  leave it unchanged, one has to do two additional tasks:
\begin{enumerate}
\item Add a generic default implementation to \texttt{func\_separate}:
 with a single line calling the orginal function \texttt{func}. This
 enables to have a unified interface, even for non specialized class.
\item Rename the original function and all its
  original specializations \texttt{func\_original}; then rename also
  the new interface simply \texttt{func}. This allows to keep the same
  interface.
\end{enumerate}
\end{remark}

\begin{remark} 
With the classical inline compiler optimizations, the overhead of
calling \texttt{rank\_separate} is limited to single supplementary
function call. Indeed all the one line additionnal methods will be
automatically inlined, except, of course, the one calling the separately
compiled code.
If this overhead is nonetheless too expensive, it suffices to enclose all the non generic specializations of
``func\_instantiate.hpp'' by a macro test. 
At compile time, the decision to separately
compile or not can be taken according to the definition of this
macro. 
\end{remark}



\bibliographystyle{plain}
\bibliography{icms} 

\end{document}
